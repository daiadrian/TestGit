kafka知识点汇总

### 分区

​		每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为**偏移量(offset)**，在每个分区中此偏移量都是唯一的

​		Kafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。<font color=blue>实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置</font>。 

​		这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，<font color=blue>消费者可以将偏移量重置为更老的一个偏移量，重新读取消息</font>。  一个消费者的操作不会影响其它消费者对此log的处理。

Kafka中采用分区的设计有几个目的：

- 一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据
- 第二，分区可以作为并行处理的单元

### 分布式

​		Log的分区被分布到集群中的多个服务器上。每个服务器处理它分到的分区。根据配置每个分区还可以复制到其它服务器作为备份容错。 每个分区有一个leader，零或多个follower

​		Leader处理此分区的所有的读写请求，而follower被动的复制数据。如果leader宕机，其它的一个follower会被推举为新的leader

​		**一台服务器可能同时是一个分区的leader，另一个分区的follower**。 这样可以平衡负载，避免所有的请求都只让一台或者某几台服务器处理

### 消费者（Consumers）

​		Kafka为  队列和发布-订阅式  模型提供了单一的消费者抽象模型： **消费者组** （consumer group）。 消费者用一个消费者组名标记自己。 

​		<font color=red>一个发布在Topic上消息被分发给此消费者组中的一个消费者</font>。 假如所有的消费者都在一个组中，那么这就变成了queue模型。 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 

​		我们可以创建一些消费者组作为逻辑上的订阅者。每个组包含数目不等的消费者， 一个组内多个消费者可以用来扩展性能和容错

​		<font color=red>**Kafka保证消息的顺序不变**</font>。 传统的队列模型保持消息，并且保证它们的先后顺序不变。但是尽管服务器保证了消息的顺序，消息还是异步的发送给各个消费者，消费者收到消息的先后顺序不能保证了。这也意味着并行消费将不能保证消息的先后顺序。

> 用过传统的消息系统的同学肯定清楚，消息的顺序处理很让人头痛。如果只让一个消费者处理消息，又违背了并行处理的初衷。 在这一点上Kafka做的更好，尽管并没有完全解决上述问题

​		Kafka采用了一种分而治之的策略：**分区**。 因为Topic分区中消息只能由消费者组中的唯一 一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也<font color=blue>仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序</font>。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区

###  Kafka的保证

- 生产者发送到一个特定的Topic的分区上，消息将会按照它们发送的顺序依次加入，也就是说，如果一个消息M1和M2使用相同的producer发送，M1先发送，那么M1将比M2的offset低，并且优先的出现在日志中。消费者收到的消息也是此顺序。（生产和消费的顺序保证）

- 如果一个Topic配置了复制因子（replication factor）为N， 那么可以允许N-1服务器宕机而不丢失任何已经提交（committed）的消息

### kafka作为一个存储系统

​		所有发布消息到消息队列和消费分离的系统，实际上都充当了一个存储系统（**发布的消息先存储起来**）。Kafka比别的系统的优势是它是一个非常高性能的存储系统。（顺序写入磁盘）

​		写入到kafka的数据将写到磁盘并复制到集群中保证容错性。并允许生产者等待消息应答，直到消息完全写入。

​		client来控制读取数据的位置。你还可以认为kafka是一种专用于高性能，低延迟，提交日志存储，复制，和传播特殊用途的**分布式文件系统**



### Kafka的使用场景

#### 网站活动追踪

​		kafka原本的使用场景：用户的活动追踪，网站的活动（网页游览，搜索或其他用户的操作信息）发布到不同的话题中心

​		这些消息可实时处理，实时监测，也可加载到Hadoop或离线处理数据仓库。每个用户页面视图都会产生非常高的量。

#### 日志聚合

​		日志聚合通常从服务器中收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理

​		Kafka抽象出文件的细节，并将日志或事件数据更清晰地抽象为消息流。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消费



### kafka高可用

​		Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据（有HA机制后，每个 broker 都有分区上的完整数据），这就是**天然的分布式消息队列**



HA机制（`hight availablity` 高可用），kafka 的副本机制（`replica`）：

​		每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。

​		写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。<font color=red>**Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性**</font>

> 为什么只能读写 leader？很简单，**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题

​		如果某个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，然后继续读写那个新的 leader 即可。这就有所谓的高可用性了

​		<font color=blue>**写数据**的时候，生产者只写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据</font>。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，**<font color=red>leader 收到所有 follower 的 ack 之后</font>**，就会返回写成功的消息给生产者。（这只是其中一种模式，还可以适当调整这个行为）

​		<font color=blue>**消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到</font>


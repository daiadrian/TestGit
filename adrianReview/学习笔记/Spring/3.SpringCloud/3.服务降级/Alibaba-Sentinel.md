# Sentinel 是什么？

​		随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性

## 主要的优点

- **<font color=orange>丰富的应用场景</font>**

  - 例如秒杀（即突发流量控制在系统容量可以承受的范围）
  - 消息削峰填谷
  - 集群流量控制
  - 实时熔断下游不可用应用等

- **<font color=orange>完备的实时监控</font>**

  - Sentinel 同时提供实时的监控功能

  - 可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况

- **<font color=orange>广泛的开源生态</font>**

  - Sentinel 提供开箱即用的与其它开源框架/库的整合模块

  - 例如与 Spring Cloud、Dubbo、gRPC 的整合。只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel

- **<font color=orange>完善的 SPI 扩展点</font>**

  - Sentinel 提供简单易用、完善的 SPI 扩展接口
  - 可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等



## 主要特性

Sentinel 分为两个部分:

- 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持
- 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器



![1.Sentinel主要特性](.\images\1.Sentinel主要特性.png)

- 绿色部分都是 Sentinel 核心库可以做的事情



## 基本概念

1. <font color=red>**资源**</font>

   - 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容

     > 例如：
     >
     > - 由应用程序提供的服务
     > - 由应用程序调用的其它应用提供的服务
     > - 甚至可以是一段代码

   - 只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源



2. <font color=red>**规则**</font>
   - 围绕资源的实时状态设定的规则，可以包括**流量控制规则**、**熔断降级规**则以及**系统保护规则**
   - 所有规则可以动态实时调整



## 功能和设计理念

### 流量控制

​		流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。然而从系统稳定性角度考虑，在处理请求的速度上，也有非常多的讲究

​		任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的。所以需要根据系统的处理能力对流量进行控制

​		Sentinel 作为一个调配器，可以根据需要把随机的请求调整成合适的形状，如下图所示：

![Sentinel流量控制](\images\2.Sentinel流量控制.png)

#### 流量控制设计理念

Sentinel 的设计理念是可以自由选择控制的角度，并进行灵活组合，从而达到想要的效果

流量控制有以下几个角度：

- <font color=red>资源的调用关系</font>
  - 例如资源的**调用链路**，资源和资源之间的关系
- <font color=red>运行指标</font>
  - 例如 QPS、线程池、系统负载等
- <font color=red>控制的效果</font>
  - 例如直接限流、冷启动、排队等



### 熔断降级

​		除了流量控制以外，及时对调用链路中的不稳定因素进行熔断也是 Sentinel 的使命之一

​		<font color=red>由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，可能会**导致请求发生堆积，进而导致级联错误**</font>

​		Sentinel 和 Hystrix 的原则是一致的：当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间长或异常比例升高的时候，<font color=red>则**对这个资源的调用进行限制，让请求快速失败**，避免影响到其它的资源而导致级联故障</font>

#### 熔断降级设计理念

在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法

Hystrix 通过 <font color=blue>线程池隔离 </font>的方式，来对依赖（在 Sentinel 的概念中对应资源）进行了隔离

- 这样做的好处是资源和资源之间做到了最彻底的隔离
- 缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配



**<font color=orange>Sentinel 对这个问题（线程切换的成本）采取了两种手段：</font>**

1.  <font color=blue>通过并发线程数进行限制</font>
   - 和资源池隔离的方法不同，**Sentinel 通过限制资源并发线程的数量**，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小
   - 当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。**当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝**。堆积的线程完成任务后才开始继续接收请求



2.  <font color=blue>通过响应时间对资源进行降级</font>
   - 除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源
   - 当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复



### 系统自适应保护

​		Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环

​		当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用

​		针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求





# 流量控制

## 基于QPS/并发数的流量控制

流量控制主要有两种统计类型，一种是<font color=red>**统计并发线程数**</font>，另外一种则是<font color=red>**统计 QPS**</font>



### 并发线程数控制

​		**<font color=blue>并发数控制用于保护业务线程池不被慢调用耗尽</font>**

​		当应用所依赖的下游应用由于某种原因导致服务不稳定、响应延迟增加，对于调用者来说，意味着吞吐量下降和更多的线程数占用，极端情况下甚至导致线程池耗尽

​		为应对太多线程占用的情况，业内有使用隔离的方案，比如通过不同业务逻辑使用不同线程池来隔离业务自身之间的资源争抢（线程池隔离）。这种隔离方案虽然隔离性比较好，但是代价就是线程数目太多，线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响

​		Sentinel 并发控制不负责创建和管理线程池，而是简单统计当前请求上下文的线程数目（正在执行的调用数目），如果超出阈值，新的请求会被立即拒绝，效果类似于信号量隔离



### QPS流量控制

​		当 QPS 超过某个阈值的时候，则采取措施进行流量控制



## 流量控制效果

流量控制的效果包括以下几种：**直接拒绝**、**Warm Up**、**匀速排队**



### 直接拒绝

**直接拒绝**（`RuleConstant.CONTROL_BEHAVIOR_DEFAULT`）方式是默认的流量控制方式

​		当QPS超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出`FlowException`。这种方式适用于对系统处理能力确切已知的情况下，比如通过压测确定了系统的准确水位时



### Warm Up 预热启动

Warm Up（`RuleConstant.CONTROL_BEHAVIOR_WARM_UP`）方式，即预热/冷启动方式

​		当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过 "冷启动"，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮

​		简单来说就是



### 匀速排队

匀速排队（`RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER`）

​		这个方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法

​		这种方式主要用于处理间隔性突发的流量，例如消息队列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求


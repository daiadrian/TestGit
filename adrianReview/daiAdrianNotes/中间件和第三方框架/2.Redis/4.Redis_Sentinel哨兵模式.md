# 哨兵模式(Sentinel)

## 概述	

​		**<font color=blue>Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案</font>**		

​		哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，`Sentinel`（哨兵）进程是用于监控 `Redis` 集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用



## Sentinel的三个定时任务

1. 每 10 秒对个 Sentinel 对 master 和 slave 执行 info 操作
   - 确认主从关系
2. 每 2 秒每个 Sentinel 通过 master 节点的 channel 交换信息 （pub/sub 发布订阅模式）
   - 通过 `__sentinel__:hello` 频道进行交互，在 master 节点的该频道发布消息，然后其他 Sentinel 节点订阅该消息
   - 交互自身的信息和对节点的 “看法” （主观下线或者主节点选举）
3. 每秒每个 Sentinel 对其他 Sentinel 和 redis 服务进行 ping 操作
   - 心跳检测，失败判断的依据



## Sentinel进程的作用

1. <font color=blue>监控（Monitoring）</font>
   - 哨兵进程（Sentinel）会不断地检查你的Master和Slave是否运作正常（通过PING）
2. <font color=blue>提醒（Notification）</font>
   - 当被监控的某个 `Redis`节点出现问题时，哨兵（Sentinel） 可以通过 `API` 向管理员或者其他应用程序发送通知
3. <font color=blue>自动故障迁移（`Automatic failover`）</font>
   - 当一个Master不能正常工作时，哨兵（Sentinel） 会开始一次自动故障迁移操作：
     1. 它会将失效 Master 的其中一个 Slave 升级为新的 Master，并让失效 Master 的其他 Slave 改为复制新的Master
     2. 当客户端试图连接失效的 Master 时，集群也会向客户端返回新 Master 的地址，使得集群可以使用现在的 Master 替换失效 Master
     3. Master和Slave服务器切换后，Master的 `Redis.conf`、Slave的 `Redis.conf` 和  `Sentinel.conf`的配置文件的内容都会发生相应的改变，即 Master 主服务器的 `Redis.conf` 配置文件中会多一行`slaveof` 的配置，`Sentinel.conf` 的监控目标会随之调换



```xml
sentinel monitor <masterName> <ip> <port> <quorum>
<!-- 
	masterName：redis集群的名称
	ip,port 为master的地址和端口
  	quorum：客观下线的依据，指至少有 quorum 个 sentinel 主观的认为这个master有故障，才会对这个master进行下线以及故障转移
	（quorum的值一般设置为sentinel个数的二分之一加1，例如3个sentinel就设置2）
-->
    
    
sentinel down-after-milliseconds <masterName> <timeout> 
<!-- 
	这个配置就是进行主观下线的一个依据
	某个sentinel先将master节点进行一个主观下线，然后会将这个判定通过 sentinel is-master-down-by-addr 这个命令问对应的节点是否也同样认为该 addr 的 master 节点要做客观下线
	最后当达成这一共识的 sentinel 个数达到前面说的 quorum 设置的这个值时，就会对该 master 节点下线进行故障转移

默认是: sentinel down-after-milliseconds mymaster 30000 (单位是: 毫秒)
-->
```



### 主观下线

​		主观下线（Subjectively Down， 简称 SDOWN）指的是 **单个Sentinel实例** 对服务器做出的下线判断，即单个 Sentinel 认为某个Redis服务下线（有可能是接收不到订阅或者网络不通等等原因）



### 客观下线

​		客观下线（Objectively Down， 简称 ODOWN）指的是 **多个 Sentinel 实例** 在对同一个服务器做出 SDOWN （主观下线）判断， 并且通过 `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务器下线判断，然后开启 failover（故障切换）

​		只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后（超过 `quorum`（选举）个数）， 服务器才会被标记为客观下线



## Sentinel领导者选举

Sentinel 领导者是负责进行redis主节点故障转移的

选举的过程：

1.  每个做主观下线的 Sentinel 节点向其他节点发送 `SENTINEL is-master-down-by-addr` 命令，要求将它设置成领导者
2. 收到命令的 Sentinel 节点如果没有同意过其他 Sentinel 节点发送的命令，那么就会同意该命令的请求，否则就会拒绝这次命令的请求
3. 如果该 Sentinel 节点发现自己的票数已经超过了 Sentinel 集合半数并且超过了 `qnorum` ，那么它将成为领导者
4. 如果此过程中有多个 Sentinel 节点成为了领导者，那么将等待一段时间之后再进行选举 



## 故障转移

1. 选择合适的 slave 节点作为新的 master 节点
   - 选择 `slave-priority`（slave节点优先级，可配置）最高的slave节点，如果存在则返回，不存在则继续
   - 选择复制偏移量 offset 最大的 slave 节点（复制的最完整，一致性最接近的节点），如果存在则返回，不存在则继续
   - 选择 runid 最小的 slave 节点（启动最早的节点）



2. 对上一步选出的 slave 节点执行 `slavefo no one` 的命令让其成为 master 节点

3. 向剩余的 slave 节点发送命令，让它们成为新的 master 节点的 slave 节点，复制规则和 `parallel-sync` 配置有关

   - master 节点会做一次 RDB 文件的生成

   - 然后 master 节点会向 slave 节点发送该文件进行数据同步（有一定的网络开销）

   - 这个配置能够规定每次向多少个节点发送进行数据同步，同步期间还会导致 slave 不能处理其他命令

     

4. 更新对原来的 master 节点的配置为 slave，并持续保持对其关注，当其恢复正常后命令其复制新的 master 节点





## Sentinel进程的工作方式

1. 每个 Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave从服务器以及其他 Sentinel（哨兵）进程发送一个 PING 命令
2. 如果一个实例距离最后一次有效回复 PING 命令的时间超过 `is-master-down-after-milliseconds` 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为<font color=red>**主观下线**（`SDOWN`）</font>

   - 如果一个Master主服务器被标记为主观下线（`SDOWN`），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以<font color=blue>每秒一次</font>的频率确认Master主服务器的确进入了主观下线状态

   - 当有**足够数量的 Sentinel（哨兵）进程**（超过 `quorum`（选举）个数）在指定的时间范围内确认Master 主服务器进入了主观下线状态（`SDOWN`），则Master主服务器会被标记为客观下线（`ODOWN`）
3. 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master主服务器、Slave 从服务器发送 `INFO` 命令
4. 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（`ODOWN`）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave 从服务器发送 `INFO` 命令的频率会从 10 秒一次改为每秒一次
5. 若没有足够数量的 Sentinel（哨兵）进程同意 Master 主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 `PING` 命令返回有效回复，Master主服务器的主观下线状态就会被移除



## Sentinel的配置

<font color=red> **failover ： 故障切换** </font>

````xml
daemonize yes

<!-- 配置端口 -->
port 26379

<!-- 指定本地数据库存放目录 -->
dir /opt/redis/data

<!-- 日志文件 -->
logfile "26379.log"


sentinel monitor <masterName> <ip> <port> <quorum>
<!-- 
	masterName：redis集群的名称
	ip,port 为master的地址和端口
  	quorum：客观下线的依据，指至少有 quorum 个 sentinel 主观的认为这个master有故障，才会对这个master进行下线以及故障转移（quorum的值一般设置为sentinel个数的二分之一加1，例如3个sentinel就设置2）
-->
    
    
sentinel down-after-milliseconds <masterName> <timeout> 
<!-- 
	这个配置就是进行主观下线的一个依据
	某个sentinel先将master节点进行一个主观下线，然后会将这个判定通过 sentinel is-master-down-by-addr 这个命令问对应的节点是否也同样认为该 addr 的 master 节点要做客观下线
	最后当达成这一共识的 sentinel 个数达到前面说的 quorum 设置的这个值时，就会对该 master 节点下线进行故障转移

默认是: sentinel down-after-milliseconds mymaster 30000 (单位是: 毫秒)
-->
  
    
sentinel parallel-syncs <master-name> <numslaves> 
<!--
	这个配置项指定了在发生 failover 主备切换时最多可以有多少个 slave 同时对新的 master 进行同步
	这个数字越小，完成 failover 所需的时间就越长。但是如果这个数字越大，就意味着越多的 slave 因为 replication(复制) 而不可用
	可以通过将这个值设为 1 来保证每次只有一个 slave 处于不能处理命令请求的状态 (即进行顺序执行)	
-->    
    

sentinel failover-timeout <master-name> <milliseconds>
<!--
failover-timeout 可以用在以下这些方面： 
	1. 同一个 sentinel 对同一个 master 两次 failover 之间的间隔时间
	2. 当一个 slave 从一个错误的 master 那里同步数据开始计算时间。直到 slave 被纠正为向正确的 master那里同步数据的时间
	3.当想要取消一个正在进行的 failover 所需要的时间  
	4.当进行 failover 时，配置所有 slaves 指向新的 master 所需的最大时间。不过即使过了这个超时，slaves 依然会被正确配置为指向master，但是就不按 parallel-syncs 所配置的规则来了	
-->  
    
````



### 配置注意事项

1. 只有Sentinel 集群中大多数服务器认定master主观下线时master才会被认定为客观下线，才可以进行故障迁移

   - 也就是说：即使不管我们在sentinel monitor中 `quorum` 设置的数是多少，就算是满足了该值，只要达不到大多数，就不会发生故障迁移

   

2. 官方建议 sentinel 至少部署三台，且分布在不同机器

   - 这里主要考虑到sentinel的可用性，假如我们只部署了两台sentinel，且`quorum`设置为1，也可以实现自动故障迁移
   - 但假如其中一台sentinel挂了，就永远不会触发自动故障迁移，因为永远达不到大多数sentinel认定master主观下线了

   ​	

3. `sentinel monitor` 配置中的master IP尽量不要写127.0.0.1或localhost

   - 因为客户端（如Jedis）获取master是根据这个获取的，若这样配置，jedis获取的ip则是127.0.0.1，这样就可能导致程序连接不上master

   

4. 当 sentinel 启动后会自动的修改 `sentinel.conf`文件，如已发现的master的slave信息，和集群中其它sentinel 的信息等，这样即使重启sentinel也能保持原来的状态

   - 当集群服务器调整时，如更换 sentinel 的机器，或者新配置一个sentinel，请不要直接复制原来运行的sentinel 配置文件，因为其里面自动生成了以上说的那些信息，我们应该复制一个新的配置文件或者把自动生成的信息给删掉

     

5. 当发生故障迁移的时候，master的变更记录与slave更换master的修改会自动同步到redis的配置文件，这样即使重启redis也能保持变更后的状态





## 哨兵主备切换的数据丢失问题

哨兵进行**<font color=red>主备切换的过程</font>**，可能会导致数据丢失



### 异步复制导致的数据丢失

​		因为 master->slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了

![async-replication-data-lose-case](/images/4.哨兵模式1.png)

### 脑裂导致的数据丢失

​		某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**

​		此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据

​		因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了

![redis-cluster-split-brain](/images/4.哨兵模式2.png)

### 数据丢失问题的解决方案

进行如下配置：

```bash
min-slaves-to-write 1
min-slaves-max-lag 10
```

配置项表示：<font color=red>要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒</font>

​		如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了

- `min-slaves-max-lag` 这个配置，就可以确保说：
  - 一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内

- 如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说：
  - 如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据





## 哨兵模式的优缺点

**优点：**

- 哨兵集群模式是基于主从模式的，所有主从的优点，哨兵模式同样具有
- 主从可以切换，故障可以转移，系统可用性更好
- 哨兵模式是主从模式的升级，系统更健壮，可用性更高

**缺点：**

- `Redis` 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费
- 配置复杂





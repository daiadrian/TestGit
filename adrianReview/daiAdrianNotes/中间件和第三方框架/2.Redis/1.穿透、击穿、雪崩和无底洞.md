# 缓存穿透和击穿

## 缓存穿透

​		缓存穿透指的是<font color=red>**对一个不存在的数据进行请求**</font>，该请求将会 **穿透缓存到达数据库**。即缓存和数据库层面都不会命中的数据



### 缓存穿透带来的问题

1. 缓存穿透将导致不存在的数据每次请求都要到存储层去查询，**失去了缓存保护后端存储服务的意义**

2. 缓存穿透问题可能会**使后端存储负载加大**，由于很多后端存储不具备高并发性，甚至可能造成后端存储服务宕掉
   - 通常可以<font color=blue>在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题</font>



### 穿透的优化方案

#### 1.缓存空对象

对这些不存在的数据缓存一个空数据

- 每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN`
- 然后设置一个过期时间，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据



<font color=blue>**缓存空对象带来的问题**</font>

1. 空值做了缓存，意味着缓存层中存了更多的键，**需要更多的内存空间**（如果是攻击，问题更严重）
   - 比较有效的方法是针对这类数据**设置一个较短的过期时间，让其自动剔除**
2. **缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响**
   - 例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以**利用消息系统或者其他方式清除掉缓存层中的空对象**



#### 2.布隆过滤器

对这类请求进行过滤（布隆过滤器）





#### 两种方案的比较

| 方案       | 适用场景                               | 维护成本                                       |
| ---------- | -------------------------------------- | ---------------------------------------------- |
| 缓存空对象 | 1.数据命中不高；2.数据频繁变化实时性高 | 代码维护简单；需要过多的缓存空间；数据一致性低 |
| 布隆过滤器 | 1.数据命中不高；2.数据相对固定实时性低 | 代码维护复杂；缓存空间占用少                   |





## 缓存击穿

​		缓存击穿指某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，**<font color=red>当这个 key 在失效的瞬间</font>，大量的请求就击穿了缓存，直接请求数据库，然后再大量的来重建这个热点key的缓存数据**



### 击穿的优化方案

- 可以将热点数据设置为永远不过期
- 基于 Redis 或者 Zookeeper 实现互斥锁，等待第一个请求构建完热点key的缓存数据之后，再释放锁，进而其它请求才能通过该 key 访问数据



## 缓存穿透和缓存击穿的区别

缓存穿透和缓存击穿最主要的区别是：

- 缓存击穿是 <font color=red>**key 在失效瞬间 **</font>有大量请求击穿了缓存
- 缓存穿透是缓存中没有相应的 key 而直接去查询了数据库





# 缓存雪崩

​		缓存雪崩指的是<font color=red>由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，**导致大量的请求都到达数据库，造成数据库级联宕机**的情况</font>

​		在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃



## 雪崩的优化方案

2. <font color=red>**保证缓存层服务高可用性**</font>
   - 可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据
   - 当某个节点宕机时可以保证其它节点的缓存仍然可用

3. <font color=red>**进行缓存预热**</font>
- 即系统启动前加载一些热点数据到缓存中
   
- 避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩
   
4. <font color=red>**系统应用进行请求的限流/降级操作**</font>
   - 限制接口的QPS
   - 系统应用中使用降级的机制，且让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响





# 缓存“无底洞”现象

​		缓存 “无底洞”  指的是为了满足业务要求，添加了大量缓存节点，<font color=red>但是性能**不但没有好转反而下降了**的现象</font>



## 产生的原因

​		缓存系统为了满足业务大量加节点，然后通常采用 hash 函数将 key 映射到对应的缓存节点，造成 key 的分布与业务无关

​		但是**由于数据量和访问量的持续增长，造成<font color=red>需要添加大量节点做水平扩容，导致键值分布到更多的节点上</font>**。所以无论是 `Memcache` 还是 `Redis` 的分布式环境，批量操作通常 **需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，<font color=blue>分布式批量操作会涉及多次网络时间</font>**

​		客户端的一次批量操作（例如 `mget` 操作）会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。网络连接数变多，对节点的性能也有一定影响



## 无底洞问题优化方案

<font color=blue>**优化思路：**</font>

- 命令本身的优化，例如优化SQL语句等
- 减少网络通信次数
- 降低接入成本，例如客户端使用长连接或者连接池、NIO等





### 1.串行命令

​		假设 n 个 key 是比较均匀地分布在 `Redis Cluster` 的各个节点上，因此无法使用 `mget` 命令一次性获取到所有分片的数据的

所以通常来讲要获取 n 个 key 的值，最简单的方法就是逐次执行 n 个 get 命令

这种操作**时间复杂度较高**，它的<font color=red>操作时间 = n次网络时间 + n次命令时间，网络次数是 n</font>



### 2.串行IO

​		`Redis Cluster` 是使用了 CRC16 算法计算出散列值，再对 16383 的取余数就可以算出这个 key 对应的 slot 值，Smart 客户端会保存 slot 和节点的对应关系

​		有了这两个数据就可以**将属于同一个节点的key进行归档，得到每个节点的key子列表，之后对每个节点执行 `mget` 或者 `pipeline` 操作**

它的 <font color=red>操作时间 = node次网络时间 + n次命令时间，网络次数是 node 的个数，**node是指需要查询的 node 节点数**</font>



### 3.并行IO

​		此方案是将串行IO中的**最后一步改为多线程执行，网络次数虽然还是节点个数，**但由于使用多线程网络时间变为O(1)，但是这种方案会增加编程的复杂度

它的 <font color=red>操作时间 = **max_slow(node网络时间)**+n次命令时间。`max_slow` 指的是并行查询中最慢的那个节点的网络时间</font>



### 4.hash_tag实现

​		`Redis Cluster`的**hash_tag功能**，它可以将多个key强制分配到 一个节点上

它的 <font color=red>操作时间=1次网络时间+n次命令时间</font>



### 方案的比较

| 方案     | 优点                                 | 缺点                                   | 网络IO            |
| -------- | ------------------------------------ | -------------------------------------- | ----------------- |
| 串行命令 | 编程简单，**少量key**的时候性能较好  | 大量keys的时候请求延迟严重             | O(keys)           |
| 串行IO   | 编程简单，**节点较少**的时候性能较好 | 节点较多的时候请求延迟严重             | O(nodes)          |
| 并行IO   | 延迟取决于并行时最慢的节点           | 编程复杂；由于多线程，定位问题时比较难 | O(max_slow(node)) |
| hash_tag | 性能最高                             | 业务维护成本高，容易出现数据倾斜       | O(1)              |

> 数据倾斜：大量的相同 key 被分配到一个分区里，造成了一个分区存储压力较大，而其他分区空闲较多的情况
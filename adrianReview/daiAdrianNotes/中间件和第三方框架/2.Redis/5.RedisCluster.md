# 数据分区

分区是分割数据到多个 Redis 实例的处理过程，因此每个实例只保存 key 的一个子集



## 分区的优势

- 通过利用多台计算机内存的和值，构造更大的数据库
- 通过多核和多台计算机，扩展计算能力
- 通过多台计算机和网络适配器，扩展网络带宽



## 分区的不足

- 涉及多个key的操作通常是不被支持的

  - 例如，当两个set映射到不同的redis实例上时，就不能对这两个 set 执行交集操作

    

- 涉及多个key的Redis事务不能使用

- 当使用分区时，数据处理较为复杂

  - 例如：需要处理多个 RDB/AOF 文件，并且从多个实例和主机备份持久化文件

    

- 增加或删除容量也比较复杂。Redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性



## 分区类型

### 范围分区（顺序分区）

​		最简单的分区方式是按范围分区，也叫顺序分区，即映射一定范围的对象到特定的Redis实例

​		<font color=blue>特点是：数据分散度易倾斜（表示数据访问分散不均匀），键值业务相关，可顺序访问</font>

​		比如，ID从0到10000的用户会保存到实例R0，ID从10001到 20000的用户会保存到R1，以此类推

​		这种方式是可行的，并且在实际中使用，不足就是要有一个区间范围到实例的映射表。这个表要被管理，同时还需要各种对象的映射表，通常对Redis来说并非是好的方法



### 哈希分区

<font color=blue>特点是：数据分散度高，无法顺序访问，支持批量操作</font>



#### 节点取余分区

​		这种哈希分区的方式是，采用 hash 然后根据节点数取余的方式计算存放的分区实例	

例如：（假如有三台机子）

- 用一个 hash 函数将 key 转换为一个数字，比如使用 CRC32 hash 函数。对 key 值 `dai` 执行 `crc32(dai)`会输出一个整数
- 然后对这个整数取模，将其转化为 0-1 之间的数字，就可以将这个整数映射到 3 个 Redis 实例中的一个了
- 假如 （整数 % 3 = 2），就是说 key 值为 `dai` 的应该被存到 R2 实例中。注意：取模操作是取除的余数



<font color=red>**节点取余的优缺点**</font>

优点：

- 就是实现相对简单，一般采用预分区的方式，提前根据数据量规划好分区数

缺点是：

- 当需要增加新的机器去提升整体容量的时候，加一台新的机器需要对现有的数据进行迁移，需要对所有数据进行重新 hash 再取余的方式放到实例中，这样起码需要迁移 80% 的数据量
- 如果进行翻倍的扩容方式（即3台机器变成6台），这样导致迁移的数据量是 50% 左右，大大减少需要迁移的数据量



#### 一致性哈希分区

​		基本原则：为系统中每个节点分配一个 token，范围一般在0~2的32次方，这些 token 构成哈希环。数据读写执行节点查找操作时，先根据 key 计算 hash 值，然后顺时针找到第一个大于等于该哈希值的 token 节点。例如，按照顺时针的原则，当 key 的 hash 出现在 node1 和 node2 之间，则该key就对属于node2（**顺时针取值**）

![一致性哈希分区](\images\6.一致性哈希分区.png)





<font color=red>**一致性哈希的优缺点**</font>

**优点：**

- 增加新的或者删除旧的分区时，只影响邻近的节点，但是还是有部分数据迁移



**缺点：**

- 加减节点会造成哈希环中部分数据无法命中，需要手动处理或者忽略这些数据，常用于缓存场景

  - 因为加入新的节点之后，假设在 node1 和 2 之间加入 node5 ，那么原来缓存在 node2 的部分数据，以后只能从 node5 中获取，但是新加入的 node5 中没有数据，需要手动处理数据或者重新缓存

  - 这里也侧向说明一致性哈希的优点是只有部分的数据发生迁移

    

- 当使用少量节点时，节点变化将大范围影响哈希环中数据映射，因此不适合少量数据节点的分布式方案

- 普通的一致性哈希分区在增减节点时需要增加一倍或者减少一半，能够保障最小的迁移数据和负载均衡（也就是最好是使用翻倍扩容/缩容的方式）



#### 虚拟槽分区

​		虚拟槽使用良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）

​		这个范围远远大于节点数，比如 Redis Cluster 槽的范围是 0~16383，槽是集群内数据管理和迁移的基本单位。采用大范围的槽的主要目的是为了方便数据的拆分和集群的扩展，每一个节点（Redis实例）负责维护一部分槽以及该槽所映射的键值数据

> 例如：
>
> ​		0-16383的槽分成五分，对应 5 个 node 节点实例。当一个数据进来时，对这个 key 进行 CRC16(key) 的哈希之后，然后对其进行取余的运算，即 `CRC16(key) % 16383` ，然后 Redis Cluster 会发送该数据到所有节点上；节点会判断该槽是否属于自己维护，如果是那么会保存这份数据，否则不保存这份数据并且返回告知哪个节点负责这个槽



**虚拟槽分区的特点：**

1. 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度

2. 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据

3. 支持节点，槽，键之间的映射关系，用于数据路由、在线伸缩等场景



# Redis Cluster

​		Redis Cluster是 Redis 的分布式解决方案，有效地解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用 Cluster 架构方案达到负载均衡的目的

​		**Redis Cluser采用虚拟槽分区，所有的键根据哈希函数映射到0~16383整数槽内**





## 集群模式的功能限制

Redis集群相对单机在功能上存在一些限制， 在使用时需要做好规避。限制如下：

- **key批量操作支持有限**

  - 如 `mset`、`mge`t，目前只支持具有相同 slot 值的 key 执行批量操作

  - 对于映射为不同 slot 值的 ke y由于执行 mget、mget 等操作可能存在于多个节点上因此不被支持

    

- **key事务操作支持有限**

  - 同理只支持多 key 在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能

  

- key作为数据分区的最小粒度，因此**不能将一个大的键值对象如 hash、list等映射到不同的节点**

- **不支持多数据库空间**
  
  - <font color=blue>单机下的 Redis 可以支持16个数据库，集群模式下只能使用一个数据库空间，**即 db0**</font>
- **复制结构只支持一层**，从节点只能复制主节点，不支持嵌套树状复制结构



## 安装和配置

### 原生安装

说明：一共 3 主 3 从

1. Redis 实例配置文件

   ```shell
   # redis 基本配置
   port 7000
   daemonize yes
   pidfile /var/run/redis-7000.pid
   dir /opt/redis-cluster/data
   logfile "7000.log"
   dbfilename "dump-7000.rdb"
   
   # 集群开关，默认是不开启集群模式。
   cluster-enabled yes
    
   # 集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息
   # 这个文件并不需要手动配置，这个配置文件由 Redis 生成并更新，每个 Redis 集群节点都需要一个单独的配置文件
   # 请确保与实例运行的系统中配置文件名称不冲突
   cluster-config-file nodes-7000.conf
    
   # 默认情况下，集群全部的 slot 都有节点负责，集群状态才为 ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务
   # 不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致
   # 关闭这个配置的意思就是有一个节点挂了，这个集群还能继续使用
   cluster-require-full-coverage no
   ```

2. 启动 redis 实例

   ```shell
   redis-server redis-7000.conf
   redis-server redis-7001.conf
   redis-server redis-7002.conf
   redis-server redis-7003.conf
   redis-server redis-7004.conf
   redis-server redis-7005.conf
   ```

3. 查看集群中节点的信息和集群的信息

   ```properties
   # 节点信息
   redis-cli -p 7000 cluster nodes
   
   #集群信息
   redis-cli -p 7000 cluster ninfo
   #输出
   cluster_state:fail            #集群状态
   cluster_slots_assigned:0      #被分配的槽位数
   cluster_slots_ok:0            #正确分配的槽位 
   cluster_slots_pfail:0
   cluster_slots_fail:0
   cluster_known_nodes:1         #当前集群下的所有节点，包括主从节点
   cluster_size:0                #当前集群下的有槽位分配的节点，即主节点
   cluster_current_epoch:0
   cluster_my_epoch:0
   cluster_stats_messages_sent:0
   cluster_stats_messages_received:0
   ```

4. <font color=red>**配置节点间的互联互通**</font>

   ```shell
   # 只需要其中一台机 meet 集群中的其他机器，其他机器之间就能够互相通信了
   redis-cli -p 7000 cluster meet 127.0.0.1 7001
   redis-cli -p 7000 cluster meet 127.0.0.1 7002
   redis-cli -p 7000 cluster meet 127.0.0.1 7003
   redis-cli -p 7000 cluster meet 127.0.0.1 7004
   redis-cli -p 7000 cluster meet 127.0.0.1 7005
   ```

5. <font color=red>**为集群节点分配哈希槽**</font>

   - 利用脚本分配槽

   ```shell
   #!/bin/bash
   start=$1
   end=$2
   port=$3
   for slot in `seq $1 $2`  
   do  
       echo "slot:${slot}"
       redis-cli -p ${port} cluster addslots ${slot}
   done
   ```

   ```shell
   sh addslots.sh 0 5461 7000
   sh addslots.sh 5462 10922 7001
   sh addslots.sh 10923 16383 7002
   ```

   - 利用命令分配槽

   ```shell
   redis-cli -p 7000 cluster addslots {0..5461}
   redis-cli -p 7001 cluster addslots {5462..10922}
   redis-cli -p 7002 cluster addslots {10923..16383}
   ```

   

6. <font color=red>**主从节点分配**</font>

   ```shell
   # 其中 {node-id-port} 这个值是对应节点的 node-id 
   # 这个ID值可以通过获取节点的信息来获取
   # 即执行命令：redis-cli -p 7000 cluster nodes 即可获取到对应的节点的node-id
   redis-cli -p 7003 cluster replicate {node-id-7000}
   redis-cli -p 7004 cluster replicate {node-id-7001}
   redis-cli -p 7005 cluster replicate {node-id-7002}
   ```

7. 查看槽的分配信息

   ```shell
   redis-cli -p 7000 cluster slots
   ```



### Ruby安装（官方工具）

1. Redis 实例的配置和启动，参考原生安装
2. 安装 Ruby 环境





### redis-cli命令搭建集群

​		`redis-cli --cluster` 命令本来是由 redis-trib.rb 工具提供的，但是随着发展，redis-trib.rb 工具的功能被逐渐归纳到redis-cli工具中了

创建集群

1. `--cluster-replicas 1`

   - 指定集群中每个主节点配备几个从节点，这里设置为1
   - 并且该命令会自己创建主节点和分配从节点，其中前3个是主节点，后3个是从节点，后3个从节点分别复制前3个主节点

   ```shell
   # 创建3个集群主节点和3个集群从节点
   redis-cli --cluster create --cluster-replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
   ```

   

2. `--cluster create`

   - 如果只想创建主节点，而不同时创建从节点

   ```shell
   # 只创建3个集群主节点
   redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
   ```

3. 集群完整性检查

   - 集群完整性指所有的槽都分配到存活的主节点上，只要 16384 个槽中有一个没有分配给节点则表示集群不完整
   - 可以使用下面的命令检测之前创建的集群是否成功，check 命令只需要给出集群中任意一个节点地址就可以完成整个集群的检查工作

   ```shell
   redis-cli --cluster check 127.0.0.1:7000
   ```





## 集群伸缩

​		集群的伸缩也就是加入新的节点和去除一些已有的节点，也就是扩容和缩容的操作；这一系列的操作的原理是<font color=red>**集群中槽和对应数据在节点之间的移动**</font>



### 集群扩容

**扩容是分布式存储最常见的需求，Redis集群扩容操作可分为如下步骤：**

1. <font color=blue>**准备新节点**</font>
   
- 7006 和 7007 节点
   
2. <font color=blue>**加入集群**</font>

   - 新节点采用 `cluster meet` 命令加入到现有集群中

     - 建议使用 `redis-cli --cluster`  加入集群

     - <font color=red>因为 meet 命令如果加入已经存在于其他集群的节点，会造成被加入节点的集群合并到现有集群的情况，从而造成数据丢失和错乱</font>

       

   - 新节点刚开始都是主节点状态，但是由于没有负责的槽，所以不能接受任何读写操作。**对于新节点的后续操作我们一般会有两种选择：**

     - 为它迁移槽和数据实现扩容

     - 作为其他主节点的从节点负责故障转移

       

   - 新节点加入集群（**redis-cli --cluster命令实现加入集群**）

     - 注意：<font color=red>该命令内部会执行新节点状态检查，**如果新节点已经加入其他集群或者包含数据，则放弃集群加入操作**</font>
     - `existing_host:existing_port` 是集群中已有的一个节点
     - `--cluster-slave` 和 `--cluster-master-id` 是可选的，在设置从节点的时候才会用。如果不指定 `--cluster-master-id` 则会随机分配到任意一个主节点

     ```shell
     #主要的命令
     redis-cli --cluster add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id <arg>
      
     # 将7006添加到7000所在的集群中
     redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 
     # 将7007加入到7000所属的集群中,并且作为 7000 的从节点,这种就是负责故障转移用的
     redis-cli --cluster add-node 127.0.0.1:7007 127.0.0.1:7000 --cluster-slave --cluster-master-id {node-id-7000}
     ```

     

3. <font color=blue>**迁移槽和数据**</font>

   - 槽是Redis集群管理数据的基本单位

   - **首先需要为新节点制定槽的迁移计划，确定原有节点的哪些槽需要迁移到新节点**。迁移计划需要确保每个节点负责相似数量的槽，从而保证各节点的数据均匀

   - 使用 `redis-cli cluster` 进行槽迁移

     ```shell
     redis-cli --cluster reshard host:port --from <arg> --to <arg> --slots <arg> --yes --timeout <arg> --pipeline <arg>
     ```

     - `host:port`：必传参数，集群内任意节点地址，用来获取整个集群信息
     - `--from`：制定源节点的id，如果有多个源节点，使用逗号分隔，如果是all源节点变为集群内所有主节点，在迁移过程中提示用户输入
     - `--to`：需要迁移的目标节点的id，目标节点只能填写一个，在迁移过程 中提示用户输入
     - `--slots`：需要迁移槽的总数量，在迁移过程中提示用户输入
     - `--yes`：当打印出reshard执行计划时，是否需要用户输入yes确认后再执行reshard
     - `--timeout`：控制每次migrate操作的超时时间，默认为60000毫秒
     - `--pipeline`：控制每次批量迁移键的数量，默认为10


kafka知识点汇总

## kafak简介

​		`Kafka`是最初由 `Linkedin` 公司开发，是一个分布式、分区的、多副本的、多订阅者，基于`zookeeper`  协调的分布式日志系统（也可以当做MQ系统），常见可以用于 `web/nginx` 日志、访问日志，消息服务等等（虽然支持点对点和发布订阅两种模式，但是 `kafka` 是 发布-订阅 模式）

主要应用场景是：日志收集系统和消息系统

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输
- 同时支持离线数据处理和实时数据处理
- `Scale out` 支持在线水平扩展



### Kafka优点

MQ最主要的三个优点：异步，解耦，削峰

1. 解耦

2. 冗余（数据副本）

   > ​		有些情况下，处理数据的过程会失败（数据丢失，消费异常）。除非数据被持久化，否则将造成丢失。
   >
   > ​		消息队列把数据进行**持久化**直到它们已经被完全处理，通过这一方式规避了数据丢失风险，
   >
   > ​		许多消息队列所采用的 "插入-获取-删除" 范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕

3. 灵活性&峰值处理能力（缓冲）

   > ​		在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。
   >
   > ​		使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃（削峰）

4. 高可用

5. 顺序保证

   > Kafka保证**<font color=red>一个Partition</font>**内的消息的有序性，多个分区之间不保证顺序性

6. 异步通信



### Kafka的使用场景

#### 网站活动追踪

​		kafka原本的使用场景：用户的活动追踪，网站的活动（网页游览，搜索或其他用户的操作信息）发布到不同的话题中心

​		这些消息可实时处理，实时监测，也可加载到Hadoop或离线处理数据仓库。每个用户页面视图都会产生非常高的量。

#### 日志聚合

​		日志聚合通常从服务器中收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理

​		Kafka抽象出文件的细节，并将日志或事件数据更清晰地抽象为消息流。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消费

#### 作为存储系统

​		所有发布消息到消息队列和消费分离的系统，实际上都充当了一个存储系统（**发布的消息先存储起来**）。Kafka比别的系统的优势是它是一个非常高性能的存储系统。（顺序写入磁盘）

​		写入到kafka的数据将写到磁盘并复制到集群中保证容错性。并允许生产者等待消息应答，直到消息完全写入。

​		client来控制读取数据的位置。你还可以认为kafka是一种专用于高性能，低延迟，提交日志存储，复制，和传播特殊用途的**分布式文件系统**



## kafka术语

### Broker

​		已发布的消息保存在一组服务器中，称之为Kafka集群。

​		集群中的每一个服务器都是一个**代理(Broker)**

​		消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息

### Topic

Kafka将消息种子 `Feed` 分门别类，每一类的消息称之为一个主题 `Topic`

### 分区 Partition

​		每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为**偏移量(offset)**，在每个分区中此偏移量都是唯一的

​		Kafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。<font color=blue>实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置</font>。 

​		这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，<font color=blue>消费者可以将偏移量重置为更老的一个偏移量，重新读取消息</font>。  一个消费者的操作不会影响其它消费者对此log的处理。

Kafka中采用分区的设计有几个目的：

- 一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据
- 第二，分区可以作为并行处理的单元

### 消费者和消费者组

​		Kafka为  队列和发布-订阅式  模型提供了单一的消费者抽象模型： **消费者组** （consumer group）。 消费者用一个消费者组名标记自己。 

​		<font color=red>一个发布在Topic上消息被分发给此消费者组中的一个消费者</font>。 假如所有的消费者都在一个组中，那么这就变成了queue模型。 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 

​		我们可以创建一些消费者组作为逻辑上的订阅者。每个组包含数目不等的消费者， 一个组内多个消费者可以用来扩展性能和容错

​		<font color=red>**Kafka保证消息的顺序不变**</font>。 传统的队列模型保持消息，并且保证它们的先后顺序不变。但是尽管服务器保证了消息的顺序，消息还是异步的发送给各个消费者，消费者收到消息的先后顺序不能保证了。这也意味着并行消费将不能保证消息的先后顺序。

> 用过传统的消息系统的同学肯定清楚，消息的顺序处理很让人头痛。如果只让一个消费者处理消息，又违背了并行处理的初衷。 在这一点上Kafka做的更好，尽管并没有完全解决上述问题

​		Kafka采用了一种分而治之的策略：**分区**。 因为Topic分区中消息只能由消费者组中的唯一 一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也<font color=blue>仅仅是保证Topic内的一个分区顺序处理，不能保证跨分区的消息先后处理顺序</font>。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区

## kafka架构详解

### Topics和Partition

​		Topic在逻辑上可以被认为是一个queue队列，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里

​		为了使得Kafka的吞吐率可以线性提高，物理上把Topic 分成一个或多个 Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的**所有消息和索引文件**

​		创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时也会导致更高的不可用性

​		kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中；因为每条消息都被append到该Partition中，属于**顺序写磁盘**，因此效率非常高（顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）

#### 消息持久化

​		Kafka集群会保留所有的消息，无论其被消费与否

​		因为磁盘限制，kafka 不可能永久保留所有数据，因此Kafka提供两种策略删除旧数据：基于时间和基于Partition文件大小

​		可以通过配置 `$KAFKA_HOME/config/server.properties`，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据

```properties
# 日志清理策略（delete|compact压缩）
log.cleanup.policy = delete
# 日志文件被删除的时间间隔,单位是小时。168=7*24
log.retention.hours=168
# 日志文件达到该值的数据大小时删除,单位字节
log.segment.bytes=1073741824
# 日志片段文件的检查周期，查看它们是否达到了删除策略的设置
#（log.retention.hours或log.retention.bytes）单位毫秒
log.retention.check.interval.ms=300000
# 是否开启日志压缩
log.cleaner.enable=false
```

​		因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关

​		另外，Kafka会为每一个 `Consumer Group` 保留一些 `metadata` 信息——当前消费的消息的`position(位置)`，也即 `offset`。这个offset由 `Consumer` 控制

​		正常情况下 `Consumer` 会在消费完一条消息后**递增**该 `offset`。当然，<font color=blue>`Consumer` 也可将 `offset`设成一个较小的值，重新消费一些消息</font>。因为 `offet` 由 `Consumer` 控制，所以 `Kafka broker` 是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过 `broker` 去保证同一个`Consumer Group` 只有一个 `Consumer` 能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障



### Producer消息路由

​		`Producer` 发送消息到 `broker` 时，会根据 `Paritition` 机制选择将其存储到哪一个 `Partition`。如果 `Partition` 机制设置合理，所有消息可以均匀分布到不同的 `Partition` 里，这样就实现了负载均衡

​		如果一个 `Topic` 对应一个文件，那这个文件所在的机器I/O将会成为这个 `Topic` 的性能瓶颈，而有了 `Partition` 后，不同的消息可以并行写入不同 `broker` 的不同 `Partition` 里，极大的提高了吞吐率。可以在 `$KAFKA_HOME/config/server.properties` 中<font color=red>通过配置项 `num.partitions` 来指定新建 `Topic` 的默认 `Partition` 数量，也可在创建 `Topic` 时通过参数指定，同时也可以在 `Topic` 创建之后通过Kafka提供的工具修改</font>

​		在发送一条消息时，可以指定这条消息的key，Producer 根据这个key和 `Partition` 机制来判断应该将这条消息发送到哪个 `Partition`。`Partition` 机制可以通过指定 Producer 的 `partition.class` 这一参数来指定，该class必须实现 `kafka.producer.Partitioner` 接口

### Push和Pull模式

​		push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而**<font color=red>pull模式则可以根据Consumer的消费能力以适当的速率消费消息</font>**

​		对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义



## kafka高可用(Replication)

​		Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据（有HA机制后，每个 broker 都有分区上的完整数据），这就是**天然的分布式消息队列**



HA机制（`hight availablity` 高可用），kafka 的副本机制（`replica`）：

​		每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。

​		写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。<font color=red>**Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性**</font>

> 为什么只能读写 leader？很简单，**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题

​		如果某个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，然后继续读写那个新的 leader 即可。这就有所谓的高可用性了

​		<font color=blue>**写数据**的时候，生产者只写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据</font>。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，**<font color=red>leader 收到所有 follower 的 ack 之后</font>**，就会返回写成功的消息给生产者。（这只是其中一种模式，还可以适当调整这个行为）

​		<font color=blue>**消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到</font>



### 为什么需要高可用

​		如果Producer使用同步模式则Producer会在尝试重新发送 `message.send.max.retries`（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据（会造成本应发往该Broker的**数据丢失**），也可选择继续选择发送（会造成**数据阻塞**）

　　如果Producer使用异步模式，则Producer会尝试重新发送 `message.send.max.retries`（默认值为3）次后记录该异常并继续发送后续数据，这会造成**数据丢失并且用户只能通过日志发现该问题**。同时，Kafka的Producer并未对异步模式提供callback接口

　　由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要



### kafka副本策略

​		为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是**一个Topic的Partition数量大于Broker的数量**。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。

​		实际上，如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。

Kafka分配Replica的算法如下：

1. 将所有Broker（假设共n个Broker）和待分配的Partition排序

2. 将第i个Partition分配到第（i mod n）个Broker上

3. 将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上
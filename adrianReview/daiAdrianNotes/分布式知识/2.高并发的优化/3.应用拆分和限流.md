# 应用拆分

## 拆分的原则

1. <font color=red>业务优先：</font>
   - 每个系统都会有多个模块，每个模块又有多个业务功能；按照业务边界进行切割，再对模块进行拆分

2. <font color=red>循序渐进：</font>
   - 边拆分边测试，保证系统的正常运行

3. <font color=red>兼顾技术：</font>
   - 重构、分层（不能为了分布式而分布式，拆分过程不仅是业务梳理也是代码重构的过程，根据技术进行分层来分配工作）

4. <font color=red>可靠测试：</font>
   - 测试完毕后，才可进行下一步，每一步都要有足够的测试才可进行下一步，避免小错误引起蝴蝶效应



## 应用拆分时设计和选择

1. 应用之间通信：
   - RPC ：采用RPC要求实时性高
   - 消息队列：消息队列通常用于传输数据包小但是数据量大，对实时性要求低的场景
   - API（基于RESTFul风格的接口原则）



2. 应用之间数据库设计：
   - 通常情况下，每个应用都有自己独立的数据库，如果共同使用的信息，可以考虑放在common中使用



3. 避免事务操作跨应用：
   - 分布式事务是一个很消耗资源的问题，应用之间服务分开开发，能够保持相互独立



# 应用限流

​		每个API接口都是有访问上限的，当访问频率或者并发量超过其承受范围时候，我们就必须考虑限流来保证接口的可用性或者降级可用性。即接口也需要安装上保险丝，以防止非预期的请求对系统压力过大而引起的系统瘫痪

## 衡量服务器指标的概念

### QPS

QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准（每秒查询率）

- QPS = 并发量 / 平均响应时间
- 通常QPS用来表达和衡量当前系统的负载
- 对应 fetches/sec，即每秒的响应请求数，也即是最大吞吐能力



### 响应时间（RT）

响应时间是指系统对请求作出响应的时间

- 它完整地记录了整个计算机系统处理请求的时间
- 响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度



### 吞吐量（TPS）

​		吞吐量是指系统在单位时间内处理请求的数量。通常用吞吐量作为并发系统的性能指标

​		对于没有并发的系统而言，吞吐量就是响应时间的倒数

​		对于一个有并发的系统，如果只有一个用户使用时系统的平均响应时间是 t，当有 n 个用户使用时，每个用户看到的响应时间通常并不是 n×t ，而往往比 n×t 小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加

​		实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致



### 并发量

​		并发量指系统可以同时承载的正常使用系统功能的用户的数量。对于网站系统一般会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数



## 限流简介

​		限流就是通过对并发访问/请求进行限速或一个时间窗口内的请求进行限速，从而达到保护系统的目的。一般系统可以通过压测来**预估能处理的峰值**，一旦达到设定的峰值阀值，则可以：

- 拒绝服务（定向错误页或告知资源没有了）
- 排队或等待（例如：秒杀、评论、下单）
- 降级（返回默认数据）



## 限流常见方式

1. 限制总并发数（比如数据库连接池、线程池）
2. 限制瞬时并发数（如 Nginx 的 `limit_conn` 模块，用来限制瞬时并发连接数）
3. 限制时间窗口内的平均速率（如 Guava 的 `RateLimiter`、Nginx 的 `limit_req` 模块，限制每秒的平均速率）
4. 限制远程接口调用速率
5. 限制MQ的消费速率 
6. 等等...



## 限流常用算法

### 计数器法

​		该算法主要用来限制一定时间内的总并发数，比如数据库连接池、线程池、秒杀的并发数；计数器限流只要一定时间内的总请求数超过设定的阀值则进行限流，是一种简单粗暴的总数量限流，而不是平均速率限流

​		这个方法有一个致命问题：<font color=red>**临界问题**</font>

>  		当遇到恶意请求，比如设定的阈值是1分钟内100次请求，在59秒时，瞬间请求100次，并且在60秒时请求100次，那么这个用户在1秒内请求了200次，用户可以在重置节点（就是重置计数器的值）时突发请求，而瞬间超过我们设置的速率限制，用户可能通过算法漏洞击垮我们的应用



### 滑动窗口算法

​		滑动窗口算法类似将上面计数器法的 1秒 时间拆分成若干个小窗口（此例拆分成4个窗口），每个窗口对应 250ms

​		假设用户利用上一秒最后一刻和下一秒第一刻发起瞬间的高并发请求；此时会统计前一秒中的最后750ms 和下一秒的 前250ms ，这样能够判断出用户的访问依旧超过了 1s 的访问数量，因此依然会阻拦用户的访问



### 漏桶算法

​		水（指请求）先进入到漏桶里，漏桶以一定的速度出水（接口有响应速率），当水（请求）流入速度过大会直接溢出（访问频率超过接口响应速率），然后就拒绝请求（丢弃溢出的数据包）；可以看出**漏桶算法能强行限制数据的传输速率**

​		因为漏桶的漏出速率是固定的，所以即使网络中不存在资源冲突（没有发生拥塞），漏桶算法也不能使流突发（burst）到端口速率。因此，漏桶算法对于存在突发特性的流量来说缺乏效率

![漏桶算法示意图](.\images\LeakyBucket.jpg)



### 令牌桶算法

​		随着时间流逝，系统会按恒定 1/QPS 时间间隔（单位是 ms）往桶里加入Token；如果桶已经满了就不再加了，新请求来临时会拿走一个Token，如果没有Token可拿了就阻塞（可以加入等待队列）或者拒绝服务

​		**令牌桶的好处是可以方便的改变速度**：一旦需要提高速率（应对突发传输），则按需提高放入桶中的令牌的速率.。一般会定时（比如100毫秒）往桶中增加一定数量的令牌，有些变种算法则实时的计算应该增加的令牌的数量

